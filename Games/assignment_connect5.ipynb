{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 10, graduate students 11\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [1 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state - The initial state is \n",
    "* Actions - A column number for where the player drops their playing piece. It will fall to the lowest open place for that column.\n",
    "* Transition model - Place a piece in the column that was selected by the player\n",
    "* Goal state - Create 4 pieces in a row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* **Initial state** - The initial state is \n",
    "* **Actions** - A column number for where the player drops their playing piece. It will fall to the lowest open place for that column.\n",
    "* **Transition model** - Place a piece in the column that was selected by the player\n",
    "* **Goal state** - Create 4 pieces in a row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the search space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: calculate this state space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 times \\4$) and/or changing the winning rule to connect 3 instead of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [2 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=' ')\n",
    "\n",
    "def fill_board(board):\n",
    "    s = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    i = 0\n",
    "    for row in range(len(board)):\n",
    "        for col in range(len(board[0])):\n",
    "            board[row][col] = s[i%len(s)]\n",
    "            i+=1\n",
    "\n",
    "print(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of colors for the players use 'x' and 'o' to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 'x')`, where board is the current board position and player is the player whose next move it is and who the agent should play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the board and helper functions for:\n",
    "\n",
    "* The transition model (result).\n",
    "* The utility function.\n",
    "* Check for terminal states.\n",
    "* A check for available actions.\n",
    "* A function to visualize the board.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes.\n",
    "\n",
    "Implement an agent that plays randomly and let two random agents play against each other 1000 times. How often does each player win? Is the result expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def agent_random(board, player = 'x'):\n",
    "    open_cols = []\n",
    "    for i, col in enumerate(board[0]):\n",
    "        if col == ' ':\n",
    "            open_cols.append(i)\n",
    "    return random.choice(open_cols)\n",
    "            \n",
    "# Environment methods\n",
    "def place_piece(board, col, player='x'):\n",
    "    \"\"\"Place the player piece in the col on the board\"\"\"\n",
    "    if board[0][col] != ' ':\n",
    "        return False\n",
    "    \n",
    "    next_open_row = len(board) - 1 # if the col is empty use the bottom row\n",
    "    for row in range(0, len(board)):\n",
    "        if board[row][col] != ' ':\n",
    "            next_open_row = row - 1\n",
    "            break\n",
    "            \n",
    "    board[next_open_row][col] = player\n",
    "    \n",
    "# TODO: Optimize this\n",
    "def check_series_for_winner(series):\n",
    "    \"\"\"Check if this line (could be anywhere) \n",
    "    has 4 in a row\"\"\"\n",
    "    count = 0\n",
    "    prev = ' '\n",
    "    for current_space in series:\n",
    "        if current_space != ' ' and current_space == prev:\n",
    "            count += 1\n",
    "        elif current_space != ' ' and current_space != prev:\n",
    "            count = 1\n",
    "            prev = current_space\n",
    "        elif current_space == ' ':\n",
    "            prev = ' '\n",
    "            count = 0\n",
    "        \n",
    "        if count == 4:\n",
    "            return prev\n",
    "\n",
    "def check_for_winner(board):\n",
    "    num_cols = len(board[0])\n",
    "    num_rows = len(board)\n",
    "    \n",
    "    # check columns\n",
    "    for col in range(num_cols):\n",
    "        winner = check_series_for_winner(board[:,col])\n",
    "        if winner is not None:\n",
    "            return winner\n",
    "        \n",
    "    #check rows\n",
    "    for row in range(num_rows):\n",
    "        winner = check_series_for_winner(board[row])\n",
    "        if winner is not None:\n",
    "            return winner\n",
    "    \n",
    "    # check Diags\n",
    "    for i in range(num_rows):\n",
    "        winner = check_series_for_winner(\n",
    "            np.diagonal(board, offset=i))\n",
    "        if winner is not None:\n",
    "            return winner\n",
    "        winner = check_series_for_winner(\n",
    "            np.diagonal(np.flipud(np.fliplr(board)), offset=i))\n",
    "        if winner is not None:\n",
    "            return winner\n",
    "        winner = check_series_for_winner(\n",
    "            np.diagonal(np.flipud(board), offset=i))\n",
    "        if winner is not None:\n",
    "            return winner\n",
    "        winner = check_series_for_winner(\n",
    "            np.diagonal(np.flipud(np.fliplr(np.flipud(board))), offset=i))\n",
    "        if winner is not None:\n",
    "            return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_player(player):\n",
    "    if player == 'x':\n",
    "        return 'o'\n",
    "    else:\n",
    "        return 'x'\n",
    "def play_game(player_x, player_o, board_shape = (6, 7)):\n",
    "    players_turn = 'x'\n",
    "    \n",
    "    board = empty_board(board_shape)\n",
    "    while True:\n",
    "        col = -1\n",
    "        if players_turn == 'x':\n",
    "            col = player_x(board, players_turn)\n",
    "        else:\n",
    "            col = player_o(board, players_turn)\n",
    "        place_piece(players_turn, col)\n",
    "        winner = check_for_winner(board)\n",
    "        if winner is not None:\n",
    "            return players_turn\n",
    "        players_turn = flip_player(players_turn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-1e680de56e17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplay_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_random\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_random\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-104-149e169adf64>\u001b[0m in \u001b[0;36mplay_game\u001b[1;34m(player_x, player_o, board_shape)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer_o\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayers_turn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mwinner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_for_winner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mplayers_turn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-99-4f0d0785bdcb>\u001b[0m in \u001b[0;36mcheck_for_winner\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwinner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         winner = check_series_for_winner(\n\u001b[1;32m---> 70\u001b[1;33m             np.diagonal(np.flipud(board), offset=i))\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwinner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "play_game(agent_random, agent_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [4 points]\n",
    "\n",
    "### Implement the search starting from a given board and specifying the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Describe and implement a simple move ordering strategy. How does this strategy influence the time it takes to \n",
    "make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [3 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pruning\n",
    "\n",
    "Add forward pruning to the cutoff search where you do not consider moves that have a low evaluation value after a shallow search \n",
    "(way smaller than the cuttoff value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function or different forward pruning) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [+ 1 bonus point]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [1 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+1 Bonus point].\n",
    "\n",
    "### Pure Monte Carlos Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move is? You can use Pure Monte Carlo Search or any algorithms \n",
    "that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
